{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "with open('config.json', 'r') as file:\n",
    "    config = json.load(file)\n",
    "\n",
    "DIR_DATA = config['paths']['dir_data']\n",
    "PATH_TRAIN_VAL_SPLIT = config['paths']['path_train_val_split']\n",
    "PATH_TEST_SPLIT = config['paths']['path_test_split']\n",
    "SAVE_PREPROCESSED_DIR = config['paths']['dir_preprocessed']\n",
    "\n",
    "SAVE_IMAGE_SIZE = 224\n",
    "N_AUGMENTATIONS = 5\n",
    "\n",
    "with open(PATH_TRAIN_VAL_SPLIT, 'r') as file:\n",
    "    dict_list_pid = json.load(file)\n",
    "\n",
    "with open(PATH_TEST_SPLIT, 'r') as file:\n",
    "    list_test_pid = json.load(file)\n",
    "\n",
    "list_test_pid = list(list_test_pid.keys())\n",
    "\n",
    "AUGMENTATION = A.Compose([\n",
    "    A.ColorJitter(0.2, 0.2, 0.2, 0.2, p=0.5),\n",
    "    A.CLAHE(p=0.5),\n",
    "    A.ShiftScaleRotate(\n",
    "        shift_limit=0.2,\n",
    "        scale_limit=0.0,\n",
    "        rotate_limit=20,\n",
    "        interpolation=cv2.INTER_LINEAR,\n",
    "        border_mode=cv2.BORDER_CONSTANT, value=0, p=1.\n",
    "    ),\n",
    "])\n",
    "\n",
    "preprocessing = A.Compose([\n",
    "    A.Resize(\n",
    "        SAVE_IMAGE_SIZE, SAVE_IMAGE_SIZE, interpolation=cv2.INTER_CUBIC,\n",
    "        mask_interpolation=0, always_apply=True\n",
    "    ),\n",
    "])\n",
    "\n",
    "os.makedirs(os.path.join(SAVE_PREPROCESSED_DIR, 'train'))\n",
    "os.makedirs(os.path.join(SAVE_PREPROCESSED_DIR, 'val'))\n",
    "os.makedirs(os.path.join(SAVE_PREPROCESSED_DIR, 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_image_square_with_zero_padding(image):\n",
    "    width, height = image.size\n",
    "\n",
    "    # Determine the size of the square\n",
    "    max_side = max(width, height)\n",
    "\n",
    "    # Create a new square image with black padding (0 for black in RGB or L modes)\n",
    "    if image.mode == 'RGBA':\n",
    "        image = image.convert('RGB')\n",
    "\n",
    "    if image.mode == \"RGB\":\n",
    "        padding_color = (0, 0, 0)  # Black for RGB images\n",
    "    elif image.mode == \"L\":\n",
    "        padding_color = 0  # Black for grayscale images\n",
    "\n",
    "    # Create a new square image\n",
    "    new_image = Image.new(image.mode, (max_side, max_side), padding_color)\n",
    "\n",
    "    # Calculate padding\n",
    "    padding_left = (max_side - width) // 2\n",
    "    padding_top = (max_side - height) // 2\n",
    "\n",
    "    # Paste the original image in the center of the new square image\n",
    "    new_image.paste(image, (padding_left, padding_top))\n",
    "\n",
    "    return new_image\n",
    "\n",
    "def fill_contour(img):\n",
    "        assert len(img.shape) == 2\n",
    "        assert len(np.unique(img)) == 2\n",
    "        assert img.dtype == np.uint8\n",
    "\n",
    "        out = img.copy()\n",
    "        contours, _ = cv2.findContours(out, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cv2.drawContours(out, contours, -1, 255, thickness=cv2.FILLED)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_pid_train = []\n",
    "list_pid_val = []\n",
    "for _, v in dict_list_pid.items():\n",
    "    list_pid_train.extend(v[0])\n",
    "    list_pid_val.extend(v[1])\n",
    "list_pid_train = list(set(list_pid_train))\n",
    "list_pid_val   = list(set(list_pid_val))\n",
    "\n",
    "len(list_pid_train), len(list_pid_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_pid_train = [str(int(l)) for l in list_pid_train]\n",
    "list_pid_val   = [str(int(l)) for l in list_pid_val]\n",
    "list_test_pid  = [str(int(l)) for l in list_test_pid]\n",
    "\n",
    "\n",
    "list_images = [p for p in os.listdir(DIR_DATA) if 'Annotation' not in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in tqdm(list_images):\n",
    "    pid = str(int(filename.split('_')[0]))\n",
    "    imgname = filename.split('.')[0]\n",
    "    if pid not in list_pid_train:\n",
    "        continue\n",
    "    \n",
    "    img = Image.open(os.path.join(DIR_DATA, f'{imgname}.png'))\n",
    "    ann = Image.open(os.path.join(DIR_DATA, f'{imgname}_Annotation.png'))\n",
    "    \n",
    "    assert np.array(ann).shape[:2] == np.array(img).shape[:2]\n",
    "\n",
    "    img = make_image_square_with_zero_padding(img)\n",
    "    ann = make_image_square_with_zero_padding(ann)\n",
    "\n",
    "    img = np.array(img)\n",
    "    ann = np.array(ann)\n",
    "\n",
    "    ann = fill_contour(ann)\n",
    "\n",
    "    assert ann.shape[:2] == img.shape[:2]\n",
    "\n",
    "    data = {'img': img.copy(), 'label': ann.copy()}\n",
    "    \n",
    "    for i in range(N_AUGMENTATIONS):\n",
    "        img = data['img'].copy()\n",
    "        ann = data['label'].copy()\n",
    "\n",
    "        if AUGMENTATION:\n",
    "            augmented = AUGMENTATION(image=img, mask=ann)\n",
    "            img = augmented['image']\n",
    "            ann = augmented['mask']\n",
    "        \n",
    "        img_ann = preprocessing(image=img, mask=ann)\n",
    "        img = img_ann['image']\n",
    "        ann = img_ann['mask']\n",
    "\n",
    "        np.savez(\n",
    "            os.path.join(SAVE_PREPROCESSED_DIR, \"train\", f\"{filename.split('.')[0]}_{i}.npz\"),\n",
    "            img=img, ann=ann,\n",
    "        )\n",
    "\n",
    "        img = Image.fromarray(img)\n",
    "        ann = Image.fromarray(ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in tqdm(list_images):\n",
    "    pid = str(int(filename.split('_')[0]))\n",
    "    imgname = filename.split('.')[0]\n",
    "    if pid not in list_pid_val:\n",
    "        continue\n",
    "    img = Image.open(os.path.join(DIR_DATA, f'{imgname}.png'))\n",
    "    ann = Image.open(os.path.join(DIR_DATA, f'{imgname}_Annotation.png'))\n",
    "    \n",
    "    assert np.array(ann).shape[:2] == np.array(img).shape[:2]\n",
    "\n",
    "    img = make_image_square_with_zero_padding(img)\n",
    "    ann = make_image_square_with_zero_padding(ann)\n",
    "\n",
    "    img = np.array(img)\n",
    "    ann = np.array(ann)\n",
    "\n",
    "    ann = fill_contour(ann)\n",
    "\n",
    "    assert ann.shape[:2] == img.shape[:2]\n",
    "    \n",
    "    img_ann = preprocessing(image=img, mask=ann)\n",
    "    img = img_ann['image']\n",
    "    ann = img_ann['mask']\n",
    "\n",
    "    np.savez(\n",
    "        os.path.join(SAVE_PREPROCESSED_DIR, \"val\", f\"{filename.split('.')[0]}.npz\"),\n",
    "        img=img, ann=ann,\n",
    "    )\n",
    "\n",
    "    img = Image.fromarray(img)\n",
    "    ann = Image.fromarray(ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in tqdm(list_images):\n",
    "    pid = str(int(filename.split('_')[0]))\n",
    "    imgname = filename.split('.')[0]\n",
    "    if pid not in list_test_pid:\n",
    "        continue\n",
    "    img = Image.open(os.path.join(DIR_DATA, f'{imgname}.png'))\n",
    "    ann = Image.open(os.path.join(DIR_DATA, f'{imgname}_Annotation.png'))\n",
    "    \n",
    "    assert np.array(ann).shape[:2] == np.array(img).shape[:2]\n",
    "\n",
    "    img = make_image_square_with_zero_padding(img)\n",
    "    ann = make_image_square_with_zero_padding(ann)\n",
    "\n",
    "    img = np.array(img)\n",
    "    ann = np.array(ann)\n",
    "\n",
    "    ann = fill_contour(ann)\n",
    "\n",
    "    assert ann.shape[:2] == img.shape[:2]\n",
    "    \n",
    "    img_ann = preprocessing(image=img, mask=ann)\n",
    "    img = img_ann['image']\n",
    "    ann = img_ann['mask']\n",
    "\n",
    "    np.savez(\n",
    "        os.path.join(SAVE_PREPROCESSED_DIR, \"test\", f\"{filename.split('.')[0]}.npz\"),\n",
    "        img=img, ann=ann,\n",
    "    )\n",
    "\n",
    "    img = Image.fromarray(img)\n",
    "    ann = Image.fromarray(ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(os.listdir('preprocessed_data/train')))\n",
    "print(len(os.listdir('preprocessed_data/val')))\n",
    "print(len(os.listdir('preprocessed_data/test')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "us",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
